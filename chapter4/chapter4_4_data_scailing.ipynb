{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgQdNmYRLo5ru3ElzaBf9U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hws2002/MachineLearning_PytorchNScikitLearn/blob/master/chapter4/chapter4_4_data_scailing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.4 특성 스케일 맞추기\n",
        "결정 트리와 랜덤 포레스트는 특성 스케일 조정에 대해 걱정할 필요가 없지만, 대부분의 머신 러닝과 최적화 알고리즘은 특성의 스케일이 같을 때 훨씬 성능이 좋음  \n",
        "\n",
        "예를 들어 두 개의 특성에서 첫 번째 특성이 1에서 10사이 값이고, 두 번째 특성은 1에서 10만 사이의 값이라고 치면, 2장의 아달린같은 알고리즘은 대부분 두 번째 특성에 대한 큰 오차에 맞추어 가중치를 최적화할 것.  \n",
        "\n",
        "스케일이 다른 특성을 맞추는 대표적인 방법 두 가지인 ** 정규화 ** 와 **표준화**에 대해 알아보자."
      ],
      "metadata": {
        "id": "OKvD1OO9aavt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **최소-최대 스케일 변환(정규화)**\n",
        "\n",
        "대부분의 정규화는 특성의 스케일을 [0,1] 범위에 맞추는 것을 의미함.  \n",
        "$x_{norm}^{(i)} = { x^{(i)} - x_{min} \\over x_{max} - x_{min}}$  \n",
        "이중 $x^{(i)}$ 는 특성 샘플, $x_{min}$은 특성 중에서 가장 작은 값, $x_{max}$는 가장 큰 값."
      ],
      "metadata": {
        "id": "xv8TCKlrcWd0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reGYyMHCaQcW"
      },
      "outputs": [],
      "source": [
        "# 사이킷런에 구현된 최소-최대 스케일 변환 기능은 다음과 같이 사용함\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mms = MinMaxScaler()\n",
        "X_train_norm = mms.fit_transform(X_train)\n",
        "X_test_norm = mms.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **표준화**\n",
        "* 표준화는 많은 머신 러닝 알고리즘, 특히 경사 하강법 같은 최적화 알고리즘에서 널리 사용됨.  \n",
        "* 표준화가 분포 모양을 바꾸는 것도 아니고, 정규 분포가 아닌 데이터를 정규 분포로 바꾸는 것도 아님  \n",
        "* 또한 평균이 0이고 단위 분산을 갖는 것 외에도 표준화는 이상치 정보가 유지되기 때문에 제한된 범위로 데이터를 조정하는 최소-최대 스케일 변환에 비해 알고리즘이 이상치에 덜 민감함.  \n",
        "(최소-최대 스케일 변환은 데이터셋에 비정상적으로 아주 큰 값이나 아주 작은 값이 들어 있을 때 다른 샘플들을 좁은 구간에 촘촘하게 모으게 만듬)\n",
        "\n",
        "## **표준화 공식**\n",
        "$x_{std}^{(i)} = { x^{(i)} - μ_{x} \\over σ_{x}}$  \n",
        "이중 $μ_x$는 어떤 특성의 샘플 평균이고, $σ_x$는 그에 해당하는 표준 편차임.  \n"
      ],
      "metadata": {
        "id": "sY2GaRhNdohk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# 표준화와 정규화 코드를 다음과 같이 적을 수 있음\n",
        "ex = np.array([0,1,2,3,4,5])\n",
        "print('표준화 : ', (ex - ex.mean()) / ex.std())\n",
        "print('정규화 : ', (ex - ex.min()) / (ex.max() - ex.min()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0HUQCOjdn2u",
        "outputId": "8a9e848b-93eb-4652-f238-3b2ff8c6588d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "표준화 :  [-1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011]\n",
            "정규화 :  [0.  0.2 0.4 0.6 0.8 1. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MinMaxScaler 클래스와 비슷하게 사이킷런은 표준화를 위한 클래스도 제공함\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "stdsc = StandardScaler()\n",
        "X_train_std = stdsc.fit_transform(X_train)\n",
        "X_test_std = stdsc.transform(X_test)"
      ],
      "metadata": {
        "id": "eyAGqEOPfJnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `RobustScaler`\n",
        "특성 스케일을 조정하는 다른 좋은 방법은 `RobustScaler` 임.  \n",
        "* RobustScaler는 이상치가 많이 포함된 작은 데이터셋을 다룰 떄 특히 도움이 됨.  \n",
        "예를 들어 어떠한 데이터셋에 적용된 머신 러닝 알고리즘이 과대적합되기 쉽다면 `RobustScaler`가 좋은 선택임.\n",
        "* 특성 열마다 독립적으로 작용하며 중간 값을 뺸 다음 데이터셋의 1사분위수와 3사분위수(즉, 25백분위수와 75백분위수)를 사용해서 데이터셋의 스케일을 조정함.(이로써 극단적인 값과 이상치에 영향을 덜 받음)\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html\n"
      ],
      "metadata": {
        "id": "fYL1owoOfctw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RobustScaler 사용법은 StandardScaler와 동일함\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "rbs = RobustScaler()\n",
        "X_train_robust = rbs.fit_transform(X_train)\n",
        "X_test_robust = rbs.transform(X_test)"
      ],
      "metadata": {
        "id": "KecMZLeTgfb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(ex - np.percentile(ex,50)) / (np.percentile(ex,75) - np.percentile(ex,25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4LBn8PYg5Xu",
        "outputId": "3e7f2a98-f4d0-4f95-8e3c-5d51d6158714"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1. , -0.6, -0.2,  0.2,  0.6,  1. ])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MaxAbsScaler**\n",
        "`MaxAbsScaler`는 각 특성별로 데이터를 최대 절대값으로 나눔.  \n",
        "따라서 각 특성의 최댓값은 1이 되고, 전체 특성은 [-1,1] 범위로 변경됨.\n"
      ],
      "metadata": {
        "id": "6saj0XjzhGSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "mas = MaxAbsScaler()\n",
        "X_train_maxabs = mas.fit_transform(X_train)\n",
        "X_test_maxabs = mas.transform(X_test)"
      ],
      "metadata": {
        "id": "M5ZLpwmGh2dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 넘파이를 사용해서 계산하면\n",
        "ex / np.max(np.abs(ex))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibgeev20iAkT",
        "outputId": "b4f2c4fb-a481-4809-ee1a-d3fe258126d4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0. , 0.2, 0.4, 0.6, 0.8, 1. ])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `scale()`, `minmax_scale()`, `robust_scale()`, `maxabs_scale()` 함수\n",
        "이 함수들은 1차원 배열도 입력받을 수 있음.  \n"
      ],
      "metadata": {
        "id": "XTyCljhhiQ-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import scale, minmax_scale, robust_scale, maxabs_scale\n",
        "print('StandardScaler:', scale(ex))\n",
        "print('MinMaxScaler:', minmax_scale(ex))\n",
        "print('RobustScaler:', robust_scale(ex))\n",
        "print('MaxAbsScaler:', maxabs_scale(ex))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut9n1-ariHXK",
        "outputId": "c80d6190-81fc-4643-c949-5378d2bdfbca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StandardScaler: [-1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011]\n",
            "MinMaxScaler: [0.  0.2 0.4 0.6 0.8 1. ]\n",
            "RobustScaler: [-1.  -0.6 -0.2  0.2  0.6  1. ]\n",
            "MaxAbsScaler: [0.  0.2 0.4 0.6 0.8 1. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MaxAbsScaler, maxabs_scale()은 데이터를 중앙에 맞추지 않기 때문에 희소 행렬을 사용할 수 있음.\n",
        "from scipy import sparse\n",
        "X_train_sparse = sparse.csr_matrix(X_train)\n",
        "X_train_maxabs = mas.fit_transform(X_train_sparse)"
      ],
      "metadata": {
        "id": "UZd1sTX-jl6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RobustScaler는 fit() 메서드에 희소 행렬을 사용할 수 없지만 transform() 메서드에서 변환은 가능함\n",
        "X_train_robust = rbs.transform(X_train_sparse)"
      ],
      "metadata": {
        "id": "ijJA0ojQksws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StandardScaler는 with_mean=False로 지정하면 희소 행렬을 사용할 수 있음.\n",
        "# Normalizer 클래스와 normalize()함수는 특성이 아니라 '샘플'별로 정규화를 수행함.\n",
        "# 또한 희소 행렬도 처리할 수 있음. 기본적으로 각 샘플의 L2노름이 1이 되도록 정규화함.\n",
        "from sklearn.preprocessing import Normalizer\n",
        "nrm = Normalizer()\n",
        "X_train_l2 = nrm.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "X5z4ML0il0jx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizer 클래스의 norm 매개변수에 사용할 norm을 지정할 수 있음. 'l1', 'l2'. 'max'가 가능함\n",
        "# 기본값은 'l2'임\n",
        "ex_2f = np.vstack((ex[1:],ex[1:]**2))\n",
        "ex_2f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEJiPPvImVJx",
        "outputId": "203b2ee3-276a-46b0-9dc9-1f7d05f567bb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  2,  3,  4,  5],\n",
              "       [ 1,  4,  9, 16, 25]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l2_norm = np.sqrt( np.sum(ex_2f**2, axis = 1))\n",
        "print(l2_norm)\n",
        "ex_2f / l2_norm.reshape(-1,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6GALCFSnWgb",
        "outputId": "80729be3-e01b-45c3-d1a7-0f2bffc55109"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 7.41619849 31.28897569]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.13483997, 0.26967994, 0.40451992, 0.53935989, 0.67419986],\n",
              "       [0.03196014, 0.12784055, 0.28764125, 0.51136222, 0.79900347]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l1_norm = np.sum(np.abs(ex_2f),axis = 1)\n",
        "print(l1_norm)\n",
        "ex_2f / l1_norm.reshape(-1,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn6ya1g0ntYD",
        "outputId": "af63ad69-6d51-4d24-a473-4d61200a0501"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15 55]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.06666667, 0.13333333, 0.2       , 0.26666667, 0.33333333],\n",
              "       [0.01818182, 0.07272727, 0.16363636, 0.29090909, 0.45454545]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizer(norm = 'max')는 각 샘플의 최대 절대값을 사용하여 나눔\n",
        "max_norm = np.max(np.abs(ex_2f),axis = 1)\n",
        "print(max_norm)\n",
        "ex_2f/ max_norm.reshape(-1,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmxGQ0DloNbE",
        "outputId": "76208fa8-5208-4969-b515-07599d7d9495"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 5 25]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2 , 0.4 , 0.6 , 0.8 , 1.  ],\n",
              "       [0.04, 0.16, 0.36, 0.64, 1.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}